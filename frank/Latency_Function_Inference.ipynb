{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0fa70965",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import optimize\n",
    "import scipy as sp\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.axes as axe\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "import cvxpy as cp\n",
    "import yaml\n",
    "\n",
    "import random\n",
    "from itertools import chain, combinations, tee\n",
    "import time\n",
    "\n",
    "import glob\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f799ba9",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a87615f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def station_to_city(station_name):\n",
    "    if \"East_Palo_Alto\" in station_name:\n",
    "        city_name = \"East Palo Alto\"\n",
    "    elif \"Palo_Alto\" in station_name:\n",
    "        city_name = \"Palo Alto\"\n",
    "    elif \"Menlo_Park\" in station_name:\n",
    "        city_name = \"Menlo Park\"\n",
    "    elif \"Redwood_City\" in station_name:\n",
    "        city_name = \"Redwood City\"\n",
    "    elif \"Belmont\" in station_name:\n",
    "        city_name = \"Belmont\"\n",
    "    elif \"San_Mateo\" in station_name:\n",
    "        city_name = \"San Mateo\"\n",
    "    elif \"Burlingame\" in station_name:\n",
    "        city_name = \"Burlingame\"\n",
    "    elif \"Millbrae\" in station_name:\n",
    "        city_name = \"Millbrae\"\n",
    "    else:\n",
    "        assert 1 == 0, \"There should be no other case.\"\n",
    "    return city_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f3aee2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b94c10d8",
   "metadata": {},
   "source": [
    "# Latency Function Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d650a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_path_speed = '../data/pems_speed___101_N_Sep_2024/'\n",
    "directory_path_flow = '../data/pems_flow___101_N_Sep_2024/'\n",
    "\n",
    "speed_file_list = [f for f in os.listdir(directory_path_speed) \\\n",
    "                  if os.path.isfile(os.path.join(directory_path_speed, f)) and f[-1] == 'x' and f[0] != \"~\"]\n",
    "speed_file_list.sort()\n",
    "\n",
    "flow_file_list = [speed_file[:4] + speed_file[10:] for speed_file in speed_file_list]\n",
    "# flow_file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a516c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp_list = []\n",
    "\n",
    "date_list = ['3', '4', '5', '6', '9', '10', '11', '12', '13', '16',\\\n",
    "             '17', '18', '19', '20', '23', '24', '25', '26', '27']\n",
    "\n",
    "for date in date_list:\n",
    "    for timestamp in range(24):\n",
    "        timestamp_list += ['9/' + date + '/2024 ' + str(timestamp) + ':00']\n",
    "\n",
    "# timestamp_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e63375e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"speed_file_list[0]:\", speed_file_list[0])\n",
    "# directory_path = \"../data/pems_speed___101_N_Sep_2024/\"\n",
    "# df_speed_file = pd.read_excel(directory_path + speed_file_list[0], index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163dc7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "speed_file_temp = speed_file_list[0]\n",
    "print(\"speed_file_temp:\", speed_file_temp)\n",
    "# df_speed_file_temp = pd.read_excel('../data/pems_speed___101_N_Sep_2024/001_speed___402376_Palo_Alto___main.xlsx', index_col=0)\n",
    "\n",
    "df_speed_file_temp = pd.read_excel(directory_path_speed + speed_file_temp, index_col=0)\n",
    "\n",
    "df_speed_file_temp.loc[\"9/3/2024 0:00\", \"Speed (mph)\"]\n",
    "# df_speed_file_temp.loc[\"9/3/2024 0:00\", \"Speed (mph)\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae90c083",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# directory_path = \"../data/pems_speed___101_N_Sep_2024/\"\n",
    "city_list = [\"Palo Alto\", \"East Palo Alto\", \"Redwood City\", \"Belmont\", \"San Mateo\", \"Burlingame\", \"Millbrae\"]\n",
    "\n",
    "speed_dict = {}\n",
    "\n",
    "for speed_file in speed_file_list:\n",
    "    speed_dict[speed_file[:-5]] = {}\n",
    "    \n",
    "    df_speed_file = pd.read_excel(directory_path_speed + speed_file, index_col=0)\n",
    "\n",
    "    for timestamp in timestamp_list:\n",
    "        speed_dict[speed_file[:-5]][timestamp] = df_speed_file.loc[timestamp, \"Speed (mph)\"]\n",
    "#         df_speed_file_temp.loc[\"9/3/2024 0:00\", \"Speed (mph)\"]\n",
    "\n",
    "end_time = time.time()\n",
    "print(\"Time:\", end_time - start_time)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6255b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "num_gp_lanes = 4\n",
    "\n",
    "flow_dict = {}\n",
    "\n",
    "for flow_file in flow_file_list:\n",
    "    flow_dict[flow_file[:-5]] = {}\n",
    "    \n",
    "    df_flow_file = pd.read_excel(directory_path_flow + flow_file, index_col=0)\n",
    "    \n",
    "    for timestamp in timestamp_list:\n",
    "        flow_dict[flow_file[:-5]][timestamp] = df_flow_file.loc[timestamp, \"Flow (Veh/Hour)\"] / num_gp_lanes\n",
    "        \n",
    "end_time = time.time()\n",
    "print(\"Time:\", end_time - start_time)\n",
    "\n",
    "# flow_file_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a85ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_path_latency = '../data/pems_latency_inference/'\n",
    "distance_file = \"distances_between_sensors.xlsx\"\n",
    "\n",
    "df_distance_file = pd.read_excel(directory_path_latency + distance_file, index_col=0)\n",
    "distance_dict = {}\n",
    "\n",
    "# df_distance_file.loc[\"Data Category\", \"0\"]\n",
    "# df_distance_file.loc[\"Start City\", 10]\n",
    "\n",
    "for sub_edge in list(df_distance_file.columns):\n",
    "    distance_dict[sub_edge] = {}\n",
    "    distance_dict[sub_edge][\"Start City\"] = df_distance_file.loc[\"Start City\", sub_edge]\n",
    "    distance_dict[sub_edge][\"Start Station\"] = df_distance_file.loc[\"Start Station\", sub_edge]\n",
    "    distance_dict[sub_edge][\"End Station\"] = df_distance_file.loc[\"End Station\", sub_edge]\n",
    "    distance_dict[sub_edge][\"Distance\"] = df_distance_file.loc[\"Distances Between Sensors (miles)\", sub_edge]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad5a72d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3ba717",
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_time_dict = {}\n",
    "flow_threshold = 100\n",
    "\n",
    "for city in city_list:\n",
    "    flow_time_dict[city] = []\n",
    "    \n",
    "    station_speed_list = []\n",
    "    station_speed_list += [distance_dict[sub_edge][\"Start Station\"] for sub_edge in distance_dict.keys() \\\n",
    "                           if distance_dict[sub_edge][\"Start City\"] == city]\n",
    "    station_speed_list += [distance_dict[sub_edge][\"End Station\"] for sub_edge in distance_dict.keys() \\\n",
    "                           if distance_dict[sub_edge][\"Start City\"] == city]\n",
    "    station_speed_list = list(set(station_speed_list))\n",
    "    \n",
    "    station_flow_list = [station_speed[:3] + station_speed[9:] for station_speed in station_speed_list]\n",
    "    \n",
    "    sub_edge_list = [key for key in distance_dict.keys() if distance_dict[key][\"Start City\"] == city]\n",
    "    \n",
    "#     print(station_speed_list)\n",
    "#     print()\n",
    "    \n",
    "    for timestamp in timestamp_list:\n",
    "        # TODO: Compute flow array\n",
    "#         flow_array = np.array([flow_dict[station][timestamp] for station in station_flow_list \\\n",
    "#                                if flow_dict[station][timestamp] >= flow_threshold])\n",
    "        flow_array = np.array([flow_dict[station][timestamp] for station in station_flow_list])\n",
    "        average_flow = np.mean(flow_array)\n",
    "        \n",
    "        travel_time = sum([distance_dict[sub_edge][\"Distance\"] * 2 \\\n",
    "                           / (speed_dict[distance_dict[sub_edge][\"Start Station\"]][timestamp] \\\n",
    "                              + speed_dict[distance_dict[sub_edge][\"Start Station\"]][timestamp]) \\\n",
    "                           for sub_edge in sub_edge_list])\n",
    "        \n",
    "#         # TODO: Compute travel time\n",
    "        \n",
    "        flow_time_dict[city] += [(average_flow, travel_time)]\n",
    "        \n",
    "# flow_time_dict[\"Millbrae\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39975f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def piecewise_linear(x, x0, y0, k1, k2):\n",
    "    return np.piecewise(x, [x < x0], [lambda x:k1*x + y0-k1*x0, lambda x:k2*x + y0-k2*x0])\n",
    "\n",
    "def piecewise_linear_simplified(x, x0, y0, k):\n",
    "    return np.piecewise(x, [x < x0], [lambda x:y0, lambda x:k*x + y0-k*x0])\n",
    "\n",
    "# p , e = optimize.curve_fit(piecewise_linear, x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3652263",
   "metadata": {},
   "outputs": [],
   "source": [
    "latency_params = {}\n",
    "num_flow_potential_bends = 100\n",
    "\n",
    "for city in city_list:\n",
    "    flows = np.array([flow_time_tuple[0] for flow_time_tuple in flow_time_dict[city]], dtype = float)\n",
    "    times = np.array([flow_time_tuple[1] for flow_time_tuple in flow_time_dict[city]])\n",
    "    \n",
    "    max_flow = np.max(flows)\n",
    "    min_flow = np.min(flows)\n",
    "    \n",
    "    flow_potential_bend_list = min_flow + (max_flow - min_flow) * list(range(num_flow_potential_bends))[1:]\n",
    "    best_flow_time_slope_error = []\n",
    "    \n",
    "    for flow_potential_bend in flow_potential_bend_list:\n",
    "        \n",
    "        flow_times_at_constant = [pair for pair in flow_time_dict[city] if pair[0] <= flow_potential_bend]\n",
    "        flow_times_at_slope = [pair for pair in flow_time_dict[city] if pair[0] > flow_potential_bend]\n",
    "        \n",
    "        # TODO: Set up optimization problem.\n",
    "        \n",
    "        # Variables:\n",
    "        y = cp.Variable(1)\n",
    "        m = cp.Variable(1)\n",
    "        \n",
    "        # Objectives:\n",
    "        func = 0.0\n",
    "#         func += cp.sum([])\n",
    "#         func += cp.sum([])\n",
    "        \n",
    "        # Constraints:\n",
    "        \n",
    "        \n",
    "        # Solve problem:\n",
    "        prob = cp.Problem(objective, constraints)\n",
    "        result = prob.solve()\n",
    "        \n",
    "        # Print solution:\n",
    "        \n",
    "        \n",
    "#         if best_flow_time_slope_error == []:\n",
    "            \n",
    "            \n",
    "        \n",
    "        \n",
    "    \n",
    "#     print(\"flows:\", flows)\n",
    "#     print()\n",
    "#     print(\"times:\", times)\n",
    "#     print()\n",
    "#     print()\n",
    "    \n",
    "    # params - x of junction point, y of junction point, slope of 1st segment, slope of 2nd segment\n",
    "    params, _ = optimize.curve_fit(piecewise_linear_simplified, flows, times)\n",
    "    \n",
    "    latency_params[city] = list(params)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8210fe09",
   "metadata": {},
   "outputs": [],
   "source": [
    "latency_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3d1c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flows_temp = [flow_time_tuple[0] for flow_time_tuple in flow_time_dict[\"Palo Alto\"]]\n",
    "# times_temp = [flow_time_tuple[1] for flow_time_tuple in flow_time_dict[\"Palo Alto\"]]\n",
    "\n",
    "# flows_temp = [flow_time_tuple[0] for flow_time_tuple in flow_time_dict[\"San Mateo\"]]\n",
    "# times_temp = [flow_time_tuple[1] for flow_time_tuple in flow_time_dict[\"San Mateo\"]]\n",
    "\n",
    "flows_temp = [flow_time_tuple[0] for flow_time_tuple in flow_time_dict[\"Millbrae\"]]\n",
    "times_temp = [flow_time_tuple[1] for flow_time_tuple in flow_time_dict[\"Millbrae\"]]\n",
    "\n",
    "plt.plot(flows_temp, times_temp, \"o\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615bbba3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559abe34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9316ec03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b406839",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: \n",
    "\n",
    "# Create an dict of average speeds.\n",
    "# Create a dict, from distances_between_sensors.xlsx, of distances betwen sub-edges in that city.\n",
    "\n",
    "# For each city:\n",
    "# For each date / hour timestap:\n",
    "# Find flow vector along various sub-edges of that city at that timestamp. If each flow vector < 100, \\\n",
    "# ignore that timestamp. Otherwise, compute average flow for that city at that timestamp, and divide by num_gp_lanes.\n",
    "# Compute the time necessary to travel through that city at that timestamp, \\\n",
    "# and add it to the (flow, time) tuple / array list for that city.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4da0d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d632c24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e65b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flow_thresh_low = 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76970dac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042360ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7567e31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b43c6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_path = '../data/data_income_percentage_VoT/'\n",
    "df_data = pd.read_excel(directory_path + 'data_cities_od_VoTs_demands_1.csv')\n",
    "\n",
    "dict_data = {}\n",
    "\n",
    "for column_name_full in list(df_data.columns):\n",
    "    if column_name_full == \"Data Category\":\n",
    "        categories_list = df_data[column_name_full].tolist()\n",
    "    else:\n",
    "        dict_data[int(column_name_full)] = {}\n",
    "        for category_index, category in enumerate(categories_list):\n",
    "            if category == \"Start City Index\" or category == \"End City Index\":\n",
    "                dict_data[int(column_name_full)][category] \\\n",
    "                    = int(df_data[column_name_full].tolist()[category_index])\n",
    "            elif category == \"Start City\" or category == \"End City\":\n",
    "                dict_data[int(column_name_full)][category] \\\n",
    "                    = df_data[column_name_full].tolist()[category_index]\n",
    "            else:\n",
    "#                 print(\"category:\", category)\n",
    "                dict_data[int(column_name_full)][category] \\\n",
    "                    = float(df_data[column_name_full].tolist()[category_index])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc940ee5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c19bea51",
   "metadata": {},
   "source": [
    "# Scratch Work - Piecewise Linear Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e350d0d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Link:\n",
    "# https://stackoverflow.com/questions/29382903/how-to-apply-piecewise-linear-fit-in-python\n",
    "\n",
    "x = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10 ,11, 12, 13, 14, 15], dtype=float)\n",
    "y = np.array([5, 7, 9, 11, 13, 15, 28.92, 42.81, 56.7, 70.59, 84.47, 98.36, 112.25, 126.14, 140.03])\n",
    "\n",
    "def piecewise_linear(x, x0, y0, k1, k2):\n",
    "    return np.piecewise(x, [x < x0], [lambda x:k1*x + y0-k1*x0, lambda x:k2*x + y0-k2*x0])\n",
    "\n",
    "p , e = optimize.curve_fit(piecewise_linear, x, y)\n",
    "xd = np.linspace(0, 15, 100)\n",
    "plt.plot(x, y, \"o\")\n",
    "plt.plot(xd, piecewise_linear(xd, *p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021d78c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_list = list(p)\n",
    "# p\n",
    "# e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5f0d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4256b4",
   "metadata": {},
   "source": [
    "# Scratch Work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470af285",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde84a18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
