{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0fa70965",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.axes as axe\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "import cvxpy as cp\n",
    "import yaml\n",
    "\n",
    "import random\n",
    "from itertools import chain, combinations, tee\n",
    "import time\n",
    "\n",
    "import glob\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f799ba9",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a87615f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def station_to_city(station_name):\n",
    "    if \"East_Palo_Alto\" in station_name:\n",
    "        city_name = \"East Palo Alto\"\n",
    "    elif \"Palo_Alto\" in station_name:\n",
    "        city_name = \"Palo Alto\"\n",
    "    elif \"Menlo_Park\" in station_name:\n",
    "        city_name = \"Menlo Park\"\n",
    "    elif \"Redwood_City\" in station_name:\n",
    "        city_name = \"Redwood City\"\n",
    "    elif \"Belmont\" in station_name:\n",
    "        city_name = \"Belmont\"\n",
    "    elif \"San_Mateo\" in station_name:\n",
    "        city_name = \"San Mateo\"\n",
    "    elif \"Burlingame\" in station_name:\n",
    "        city_name = \"Burlingame\"\n",
    "    elif \"Millbrae\" in station_name:\n",
    "        city_name = \"Millbrae\"\n",
    "    else:\n",
    "        assert 1 == 0, \"There should be no other case.\"\n",
    "    return city_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f3aee2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b94c10d8",
   "metadata": {},
   "source": [
    "# Latency Function Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db9ae945",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_path_speed = '../data/pems_speed___101_N_Sep_2024/'\n",
    "directory_path_flow = '../data/pems_flow___101_N_Sep_2024/'\n",
    "\n",
    "speed_file_list = [f for f in os.listdir(directory_path_speed) \\\n",
    "                  if os.path.isfile(os.path.join(directory_path_speed, f)) and f[-1] == 'x' and f[0] != \"~\"]\n",
    "speed_file_list.sort()\n",
    "\n",
    "flow_file_list = [speed_file[:4] + speed_file[10:] for speed_file in speed_file_list]\n",
    "# flow_file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7a516c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp_list = []\n",
    "\n",
    "date_list = ['3', '4', '5', '6', '9', '10', '11', '12', '13', '16',\\\n",
    "             '17', '18', '19', '20', '23', '24', '25', '26', '27']\n",
    "\n",
    "for date in date_list:\n",
    "    for timestamp in range(24):\n",
    "        timestamp_list += ['9/' + date + '/2024 ' + str(timestamp) + ':00']\n",
    "\n",
    "# timestamp_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d56f1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"speed_file_list[0]:\", speed_file_list[0])\n",
    "# directory_path = \"../data/pems_speed___101_N_Sep_2024/\"\n",
    "# df_speed_file = pd.read_excel(directory_path + speed_file_list[0], index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "726ffc75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "speed_file_temp: 001_speed___402376_Palo_Alto___main.xlsx\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "63.9"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speed_file_temp = speed_file_list[0]\n",
    "print(\"speed_file_temp:\", speed_file_temp)\n",
    "# df_speed_file_temp = pd.read_excel('../data/pems_speed___101_N_Sep_2024/001_speed___402376_Palo_Alto___main.xlsx', index_col=0)\n",
    "\n",
    "df_speed_file_temp = pd.read_excel(directory_path_speed + speed_file_temp, index_col=0)\n",
    "\n",
    "df_speed_file_temp.loc[\"9/3/2024 0:00\", \"Speed (mph)\"]\n",
    "# df_speed_file_temp.loc[\"9/3/2024 0:00\", \"Speed (mph)\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae90c083",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 7.8884642124176025\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# directory_path = \"../data/pems_speed___101_N_Sep_2024/\"\n",
    "city_list = [\"Palo Alto\", \"East Palo Alto\", \"Redwood City\", \"Belmont\", \"San Mateo\", \"Burlingame\", \"Millbrae\"]\n",
    "num_gp_lanes = 4\n",
    "\n",
    "speed_dict = {}\n",
    "\n",
    "for speed_file in speed_file_list:\n",
    "    speed_dict[speed_file[:-5]] = {}\n",
    "    \n",
    "    df_speed_file = pd.read_excel(directory_path_speed + speed_file, index_col=0)\n",
    "\n",
    "    for timestamp in timestamp_list:\n",
    "        speed_dict[speed_file[:-5]][timestamp] = df_speed_file.loc[timestamp, \"Speed (mph)\"]\n",
    "#         df_speed_file_temp.loc[\"9/3/2024 0:00\", \"Speed (mph)\"]\n",
    "\n",
    "end_time = time.time()\n",
    "print(\"Time:\", end_time - start_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27e9b86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_path_latency = '../data/pems_latency_inference/'\n",
    "distance_file = \"distances_between_sensors.xlsx\"\n",
    "\n",
    "df_distance_file = pd.read_excel(directory_path_latency + distance_file, index_col=0)\n",
    "distance_dict = {}\n",
    "\n",
    "# df_distance_file.loc[\"Data Category\", \"0\"]\n",
    "# df_distance_file.loc[\"Start City\", 10]\n",
    "\n",
    "for sub_edge in list(df_distance_file.columns):\n",
    "    distance_dict[sub_edge] = {}\n",
    "    distance_dict[sub_edge][\"Start City\"] = df_distance_file.loc[\"Start City\", sub_edge]\n",
    "    distance_dict[sub_edge][\"Start Station\"] = df_distance_file.loc[\"Start Station\", sub_edge]\n",
    "    distance_dict[sub_edge][\"End Station\"] = df_distance_file.loc[\"End Station\", sub_edge]\n",
    "    distance_dict[sub_edge][\"Distances Between Sensors (miles)\"] = \\\n",
    "        df_distance_file.loc[\"Distances Between Sensors (miles)\", sub_edge]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3c54be4d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'flow_array' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [18]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     flow_time_dict[city] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m timestamp \u001b[38;5;129;01min\u001b[39;00m timestamp_list:\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m#         flow_array = np.array()\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mflow_array\u001b[49m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m      8\u001b[0m             average_flow \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(flow_array)\n\u001b[1;32m     10\u001b[0m         flow_time_dict[city] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [(average_flow, travel_time)]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'flow_array' is not defined"
     ]
    }
   ],
   "source": [
    "flow_time_dict = {}\n",
    "\n",
    "for city in city_list:\n",
    "    flow_time_dict[city] = []\n",
    "    for timestamp in timestamp_list:\n",
    "        # TODO: Compute flow array\n",
    "#         flow_array = np.array()\n",
    "        if flow_array.shape[0] > 0:\n",
    "            average_flow = np.mean(flow_array)\n",
    "        # TODO: Compute travel time\n",
    "        flow_time_dict[city] += [(average_flow, travel_time)]\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8fbb9f0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9743103",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b406839",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: \n",
    "\n",
    "# Create an dict of average speeds.\n",
    "# Create a dict, from distances_between_sensors.xlsx, of distances betwen sub-edges in that city.\n",
    "\n",
    "# For each city:\n",
    "# For each date / hour timestap:\n",
    "# Find flow vector along various sub-edges of that city at that timestamp. If each flow vector < 100, \\\n",
    "# ignore that timestamp. Otherwise, compute average flow for that city at that timestamp, and divide by num_gp_lanes.\n",
    "# Compute the time necessary to travel through that city at that timestamp, \\\n",
    "# and add it to the (flow, time) tuple / array list for that city.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb4e3b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c172cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e65b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flow_thresh_low = 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76970dac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042360ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7567e31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b43c6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_path = '../data/data_income_percentage_VoT/'\n",
    "df_data = pd.read_excel(directory_path + 'data_cities_od_VoTs_demands_1.csv')\n",
    "\n",
    "dict_data = {}\n",
    "\n",
    "for column_name_full in list(df_data.columns):\n",
    "    if column_name_full == \"Data Category\":\n",
    "        categories_list = df_data[column_name_full].tolist()\n",
    "    else:\n",
    "        dict_data[int(column_name_full)] = {}\n",
    "        for category_index, category in enumerate(categories_list):\n",
    "            if category == \"Start City Index\" or category == \"End City Index\":\n",
    "                dict_data[int(column_name_full)][category] \\\n",
    "                    = int(df_data[column_name_full].tolist()[category_index])\n",
    "            elif category == \"Start City\" or category == \"End City\":\n",
    "                dict_data[int(column_name_full)][category] \\\n",
    "                    = df_data[column_name_full].tolist()[category_index]\n",
    "            else:\n",
    "#                 print(\"category:\", category)\n",
    "                dict_data[int(column_name_full)][category] \\\n",
    "                    = float(df_data[column_name_full].tolist()[category_index])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc940ee5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ec4256b4",
   "metadata": {},
   "source": [
    "# Scratch Work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470af285",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde84a18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
